{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 12.2 - Coding\n",
    "\n",
    "This is the coding portion of the homework assignment for Section 12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import math\n",
    "from jax import grad\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12.10 \n",
    "\n",
    "Complete the function `crit_pt_1d_newton()`, which should find a critical point of a function of one variable using Newton's method, as described in Section 12.2.3. The iterative method should follow the rule\n",
    "$$x_{k+1} = x_{k} - \\frac{f'(x_k)}{f''(x_k)}$$\n",
    "\n",
    "Your code should accept:\n",
    "\n",
    "* `f`: A twice-differentiable callable function of one variable $f: \\mathbb{R} \\to \\mathbb{R}$.\n",
    "* `x0`: An initial guess to start Newton iteration\n",
    "* `eps`: A desired level of accuracy/error tolerance $\\varepsilon$ such that $|x_{k+1} - x_{k}| < \\epsilon$ means the algorithm has converged, and should return $x_{k+1}$ as the approximate critical point.\n",
    "* `maxiter`: A maximum number of iterations the algorithm should run. If the algorithm fails to converge within this number of iterations, your code should throw a `RuntimeError` with a message indicating the algorithm's failure to converge.\n",
    "\n",
    "\n",
    "You should use `grad()` (the imported autodifferentiaion function from `jax`) to evaluate the first and second derivatives of your function `f`. \n",
    "\n",
    "If it converges, your code should return the most recent approximation $x_{k+1}$ that was found when the convergence criterion $|x_{k+1} - x_{k}| < \\epsilon$ was met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "Problem 12.10"
    ]
   },
   "outputs": [],
   "source": [
    "def crit_pt_1d_newton(\n",
    "    f: Callable[[float], float],\n",
    "    x0: float,\n",
    "    eps: float,\n",
    "    maxiter: int\n",
    ") -> float:\n",
    "    \"\"\"Estimates a critical point of the function f using\n",
    "    Newton's method:\n",
    "    \n",
    "    x_{k+1} = x_{k} - (f'(x_k)/f''(x_k))\n",
    "\n",
    "    Returns an estimated critical point x_{k+1} if \n",
    "    |x_{k+1} - x_{k}| < eps\n",
    "    \n",
    "    NOTE: All derivatives should be found using jax.grad()\n",
    "\n",
    "    Args:\n",
    "        f (Callable): A twice-differentiable callable function\n",
    "            from R->R\n",
    "        x0 (float): An initial guess for Newton's method\n",
    "        eps (float): The error tolerance \n",
    "        maxiter (int): The maximum number of iterations\n",
    "            that the iteration should run\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated critical point\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If the iteration does not converge before\n",
    "            the given maximum number of iterations\n",
    "    \"\"\"\n",
    "    f_prime = grad(f)\n",
    "    f_prime_prime = grad(f_prime)\n",
    "    x_k = x0\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "        x_k_plus = x_k - (f_prime(x_k) / f_prime_prime(x_k))\n",
    "        if np.abs(x_k_plus - x_k) < eps:\n",
    "            return x_k_plus \n",
    "        x_k = x_k_plus\n",
    "    \n",
    "    raise RuntimeError(\"Did not converge\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the inputs for Example 12.2.7. You may use it to test your function (the correct answer should be `3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOUR ANSWER:\t3.00000000\n",
      "ACTUAL ANSWER:\t3.00000000\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: (x**4 / 4) - (27 * x)\n",
    "x0 = 3.4 \n",
    "your_answer = crit_pt_1d_newton(f, x0, 1e-6, 20)\n",
    "actual_answer = 3.0 \n",
    "print(f\"YOUR ANSWER:\\t{your_answer:.8f}\")\n",
    "print(f\"ACTUAL ANSWER:\\t{actual_answer:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to add other code cells below this to test your function with different inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12.11\n",
    "\n",
    "### Part (i)\n",
    "\n",
    "#### (a)\n",
    "\n",
    "In the Markdown cell below, write an update formula in the style of to Equation (12.9) in the textbook, but for the *rootfinding* version of the secant method. Typeset any mathematical notation using LaTeX inside double dollar signs, such as:\n",
    "\n",
    "`$$ <Your Math Here> $$`.\n",
    "\n",
    "Here are some typesetting hints, since I know many of you have never done this before (it's more intuitive than you think):\n",
    "\n",
    "* For most things, you'll just type it the way you'd type it into a normal document or search engine.\n",
    "  \n",
    "  For example, the expression $f'(x) + c $ is literally typeset by the command `$$ f'(x) + c $$`\n",
    "\n",
    "* For subscripts, use an underscore `_`, followed by anything you want in the subscript in curly braces. \n",
    "  \n",
    "  So to produce something like $x_{k+1}$, use the command `$$ x_{k+1} $$`.\n",
    "\n",
    "* For superscripts/powers, use a caret `^`, followed by anything you want in the superscript/power in curly braces.\n",
    "  \n",
    "  So to produce something like $x^{y+z}$, use the command `$$ x^{y + z} $$`\n",
    "\n",
    "* For fractions, use the  `\\frac{}{}` command, where the stuff in the first curly brace is the numerator, and the stuff in the second curly brace is in the denominator.\n",
    "  \n",
    "  So, for example, you could typset $\\displaystyle \\frac{a}{b}$ as `$$ \\frac{a}{b} $$`\n",
    "\n",
    "* Entire equations may be typset using combinations of these things. For example, equation (12.9) in the textbook\n",
    "\n",
    "  $$x_{k+1} = x_{k} - f'(x_k) \\frac{x_{k} - x_{k-1}}{f'(x_{k}) - f'(x_{k-1})}$$\n",
    "\n",
    "  could be typseset as \n",
    "\n",
    "  `$$ x_{k+1} = x_{k} - f'(x_k) \\frac{ x_{k} - x_{k-1} }{ f'(x_{k}) - f'(x_{k-1}) } $$`\n",
    "\n",
    "  (BIG HINT: Your update formula for the rootfinding secant method will look eerily a lot like this one, with only some very small tweaks...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update Formula for Rootfinding Secant Method:** \n",
    "\n",
    "$$x_{k+1} = x_{k} - f(x_k) \\frac{x_{k} - x_{k-1}}{f(x_{k}) - f(x_{k-1})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "Now, with this formula in mind, in the Markdown cell below, typeset a function $f(y)$ you could use in the above algorithm for helping to approximate the solution $y$ to \n",
    "$$y = \\log_b(x)$$\n",
    "given any $b > 1$ and $x > 0$, using only basic arithmetic operations (addition, subtraction, multiplication, and division) and exponentiation.\n",
    "\n",
    "(HINT: This should be a function whose zero $y$ is exactly $\\log_b(x)$.)\n",
    "\n",
    "(HINT: Consider taking $b$ to the power of both sides of the equation $y = \\log_b(x)$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rootfinding Function for Approximating Logarithms:** \n",
    "\n",
    "$$f(y) = b^y - x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (ii)\n",
    "\n",
    "Now, code up the function `log_secant()`, which approximates the value of $ y = \\log_b(x)$ for any $x > 0$ and $b > 1$ using the secant rootfinding method you devised in part (i). You may use ONLY basic arithmetic operations and exponentiation (that is, using only `+`, `-`, `*`, `/`, and `**`, and no `numpy` or `math` functions of any sort. The use of the built-in function `abs()` for checking for convergence is acceptable).\n",
    "\n",
    "This is similar to Newton's method - also accept an error tolerance `eps` and a maximum number of iterations `maxiter`, and return an answer once the successive iterations are within `eps` of each other, and raise a `RuntimeError` with a descriptive message if the maximum number of iterations is exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "Problem 12.11"
    ]
   },
   "outputs": [],
   "source": [
    "def log_secant(\n",
    "    x: float,\n",
    "    b: float,\n",
    "    y0: float = 0.0,\n",
    "    y1: float = 1.0,\n",
    "    eps: float = 1e-6,\n",
    "    maxiter: int = 1000\n",
    ") -> float:\n",
    "    \"\"\"Approximates y = log_b(x) using a secant\n",
    "    rootfinding method.\n",
    "\n",
    "    Returns an estimate once the difference between\n",
    "    successive iterations is\n",
    "    |y_{k+1} - y_{k}| < eps.\n",
    "    \n",
    "    Args:\n",
    "        x (float): The argument of the logarithm (x > 0)\n",
    "        b (float): The base of the logarithm (b > 1)\n",
    "        y0 (float): A first initial guess to seed the\n",
    "            secant method algorithm\n",
    "            (default=0.0)\n",
    "        y1 (float): A second initial guess to seed the\n",
    "            secant method algorithm\n",
    "            (default=1.0)\n",
    "        eps (float): The error tolerance\n",
    "            (default=10^{-6})\n",
    "        maxiter (int): The maximum number of iterations\n",
    "            that the iteration should run\n",
    "            (default=1000 iterations)\n",
    "\n",
    "    Returns:\n",
    "        float: An approximation to log_b(x).\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If the iteration does not converge before\n",
    "            the given maximum number of iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    def f(y):\n",
    "        return b**y - x\n",
    "\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "        y2 = y1 - f(y1) * ((y1 - y0) / (f(y1) - f(y0)))\n",
    "\n",
    "        if np.abs(y2 - y1) < eps:\n",
    "            return y2 \n",
    "        y0 = y1 \n",
    "        y1 = y2\n",
    "    \n",
    "    raise RuntimeError(\"Did not converge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a few simple test cases. You should test your code against these too see if your algorithm produces similar results to standard numerical packages. Feel free to add to these cases to help test your code some more - these are by no means collectively exhaustive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= TEST CASE 1 =================\n",
      "Your approximation:\t2.32192809\n",
      "Actual:\t\t\t2.32192809\n",
      "\n",
      "================= TEST CASE 2 =================\n",
      "Your approximation:\t1.46830080\n",
      "Actual:\t\t\t1.46830080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"================= TEST CASE 1 =================\")\n",
    "b = 2\n",
    "x = 5\n",
    "approx = log_secant(x, b)\n",
    "exact = math.log(x, b)\n",
    "print(f\"Your approximation:\\t{approx:.8f}\")\n",
    "print(f\"Actual:\\t\\t\\t{exact:.8f}\\n\")\n",
    "\n",
    "print(\"================= TEST CASE 2 =================\")\n",
    "b = 4.6\n",
    "x = 9.4\n",
    "approx = log_secant(x, b)\n",
    "exact = math.log(x, b)\n",
    "print(f\"Your approximation:\\t{approx:.8f}\")\n",
    "print(f\"Actual:\\t\\t\\t{exact:.8f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "IMPORTANT: Please \"Restart and Run All\" and ensure there are no errors. Then, submit this .ipynb file to Gradescope."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
